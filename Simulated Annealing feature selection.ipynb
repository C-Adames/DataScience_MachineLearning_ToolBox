{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/feature-selection-with-simulated-annealing-in-python-clearly-explained-1808db14f8fa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"\n",
    "    Run random forest classification model on feature subset\n",
    "    and retrieve cross validated ROC-AUC score\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    kf = KFold(shuffle=True, n_splits=3, random_state=42)\n",
    "    cv_roc_auc_score = round(cross_val_score(clf, X, y.values.ravel(), cv=kf, \n",
    "                                             scoring=\"roc_auc\", n_jobs=-1).mean(), 3)\n",
    "\n",
    "    return cv_roc_auc_score\n",
    "\n",
    "def simulated_annealing(X_train,\n",
    "                        y_train,\n",
    "                        maxiters=50,\n",
    "                        alpha=0.85,\n",
    "                        beta=1,\n",
    "                        T_0=1,\n",
    "                        update_iters=1,\n",
    "                        temp_reduction='geometric'):\n",
    "    columns = ['Iteration', 'Feature Count', 'Feature Set', 'Metric', 'Best Metric',\n",
    "               'Acceptance Probability', 'Random Number', 'Outcome']\n",
    "    results = pd.DataFrame(index=range(maxiters), columns=columns)\n",
    "    best_subset = None\n",
    "    hash_values = set()\n",
    "    T = T_0\n",
    "    full_set = set(np.arange(len(X_train.columns)))\n",
    "\n",
    "    # Generate initial random subset based on ~50% of columns\n",
    "    curr_subset = set(random.sample(list(full_set), round(0.5 * len(full_set))))\n",
    "    X_curr = X_train.iloc[:, list(curr_subset)]\n",
    "    prev_metric = train_model(X_curr, y_train)\n",
    "    best_metric = prev_metric\n",
    "\n",
    "    for i in range(maxiters):\n",
    "        if T < 0.01:\n",
    "            print(f'Temperature {T} below threshold. Termination condition met')\n",
    "            break\n",
    "\n",
    "        while True:\n",
    "            if len(curr_subset) == len(full_set): \n",
    "                move = 'Remove'\n",
    "            elif len(curr_subset) == 2: # Not to go below 2 features\n",
    "                move = random.choice(['Add', 'Replace'])\n",
    "            else:\n",
    "                move = random.choice(['Add', 'Replace', 'Remove'])\n",
    "            \n",
    "            pending_cols = full_set.difference(curr_subset) \n",
    "            new_subset = curr_subset.copy()   \n",
    "\n",
    "            if move == 'Add':        \n",
    "                new_subset.add(random.choice(list(pending_cols)))\n",
    "            elif move == 'Replace': \n",
    "                new_subset.remove(random.choice(list(curr_subset)))\n",
    "                new_subset.add(random.choice(list(pending_cols)))\n",
    "            else:\n",
    "                new_subset.remove(random.choice(list(curr_subset)))\n",
    "                \n",
    "            if new_subset in hash_values:\n",
    "                print('Subset already visited')\n",
    "            else:\n",
    "                hash_values.add(frozenset(new_subset))\n",
    "                break\n",
    "\n",
    "        X_new = X_train.iloc[:, list(new_subset)]\n",
    "        metric = train_model(X_new, y_train)\n",
    "\n",
    "        if metric > prev_metric:\n",
    "            print('Local improvement in metric from {:8.4f} to {:8.4f} '\n",
    "                  .format(prev_metric, metric) + ' - New subset accepted')\n",
    "            outcome = 'Improved'\n",
    "            accept_prob, rnd = '-', '-'\n",
    "            prev_metric = metric\n",
    "            curr_subset = new_subset.copy()\n",
    "            \n",
    "            if metric > best_metric:\n",
    "                print('Global improvement in metric from {:8.4f} to {:8.4f} '\n",
    "                      .format(best_metric, metric) + ' - Best subset updated')\n",
    "                best_metric = metric\n",
    "                best_subset = new_subset.copy()\n",
    "                \n",
    "        else:\n",
    "            rnd = np.random.uniform()\n",
    "            diff = prev_metric - metric\n",
    "            accept_prob = np.exp(-beta * diff / T)\n",
    "\n",
    "            if rnd < accept_prob:\n",
    "                print('New subset has worse performance but still accept. Metric change' +\n",
    "                      ':{:8.4f}, Acceptance probability:{:6.4f}, Random number:{:6.4f}'\n",
    "                      .format(diff, accept_prob, rnd))\n",
    "                outcome = 'Accept'\n",
    "                prev_metric = metric\n",
    "                curr_subset = new_subset.copy()\n",
    "            else:\n",
    "                print('New subset has worse performance, therefore reject. Metric change' +\n",
    "                      ':{:8.4f}, Acceptance probability:{:6.4f}, Random number:{:6.4f}'\n",
    "                      .format(diff, accept_prob, rnd))\n",
    "                outcome = 'Reject'\n",
    "\n",
    "        results.loc[i, 'Iteration'] = i+1\n",
    "        results.loc[i, 'Feature Count'] = len(curr_subset)\n",
    "        results.loc[i, 'Feature Set'] = sorted(curr_subset)\n",
    "        results.loc[i, 'Metric'] = metric\n",
    "        results.loc[i, 'Best Metric'] = best_metric\n",
    "        results.loc[i, 'Acceptance Probability'] = accept_prob\n",
    "        results.loc[i, 'Random Number'] = rnd\n",
    "        results.loc[i, 'Outcome'] = outcome\n",
    "\n",
    "        # Temperature cooling schedule\n",
    "        if i % update_iters == 0:\n",
    "            if temp_reduction == 'geometric':\n",
    "                T = alpha * T\n",
    "            elif temp_reduction == 'linear':\n",
    "                T -= alpha\n",
    "            elif temp_reduction == 'slow decrease':\n",
    "                b = 5 # Arbitrary constant\n",
    "                T = T / (1 + b * T)\n",
    "            else:\n",
    "                raise Exception(\"Temperature reduction strategy not recognized\")\n",
    "                \n",
    "    best_subset_cols = [list(X_train.columns)[i] for i in list(best_subset)]\n",
    "    results = results.dropna(axis=0, how='all')\n",
    "\n",
    "    return results, best_metric, best_subset_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "caf47b04aaaa0fe624adbdbda6218dbf7d5d72a64bab0a2f3916f01d16da7e27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
